{"componentChunkName":"component---src-pages-examples-sql-json-content-parent-file-id-jsx","path":"/examples/sql/e397eb25-77d7-505a-8c37-7e3b9a6bd259/","result":{"data":{"jsonContent":{"id":"75e702cf-e164-5e3b-bd53-ddca2cb54b64","content":"-- {\"id\":100,\"name\":\"lb james阿道夫\",\"money\":293.899778,\"dateone\":\"2020-07-30 10:08:22\",\"age\":\"33\",\"datethree\":\"2020-07-30 10:08:22.123\",\"datesix\":\"2020-07-30 10:08:22.123456\",\"datenigth\":\"2020-07-30 10:08:22.123456789\",\"dtdate\":\"2020-07-30\",\"dttime\":\"10:08:22\"}\r\nCREATE TABLE source_ods_fact_user_ippv (\r\n    id INT\r\n    , name STRING\r\n    , money decimal\r\n    , dateone timestamp\r\n    , age bigint\r\n    , datethree timestamp\r\n    , datesix timestamp(6)\r\n    , datenigth timestamp(9)\r\n    , dtdate date\r\n    , dttime time\r\n\r\n    , `partition` BIGINT METADATA VIRTUAL -- from Kafka connector\r\n    , `topic` STRING METADATA VIRTUAL -- from Kafka connector\r\n    , `leader-epoch` int METADATA VIRTUAL -- from Kafka connector\r\n    , `offset` BIGINT METADATA VIRTUAL  -- from Kafka connector\r\n    , ts TIMESTAMP(3) METADATA FROM 'timestamp' -- from Kafka connector\r\n    , `timestamp-type` STRING METADATA VIRTUAL  -- from Kafka connector\r\n    , partition_id BIGINT METADATA FROM 'partition' VIRTUAL   -- from Kafka connector\r\n\r\n    , WATERMARK FOR datethree AS datethree - INTERVAL '5' SECOND\r\n) WITH (\r\n      'connector' = 'kafka-x'\r\n      ,'topic' = 'user_behavior'\r\n      ,'properties.bootstrap.servers' = 'localhost:9092'\r\n      ,'properties.group.id' = 'luna_g'\r\n      ,'scan.startup.mode' = 'earliest-offset'\r\n      ,'format' = 'json'\r\n      ,'json.timestamp-format.standard' = 'SQL'\r\n      ,'scan.parallelism' = '1'\r\n      );\r\n\r\n\r\nCREATE TABLE sink\r\n(\r\n    id          int,\r\n    name        varchar,\r\n    money       decimal,\r\n    age         bigint,\r\n    datethree   timestamp,\r\n    datesix     timestamp\r\n) WITH (\r\n       -- 'connector' = 'stream-x'\r\n\r\n      'connector' = 'mysql-x',\r\n      'url' = 'jdbc:mysql://localhost:3306/test',\r\n      'table-name' = 'flink_type',\r\n      'username' = 'root',\r\n      'password' = 'abc123',\r\n\r\n      'sink.buffer-flush.max-rows' = '1024', -- 批量写数据条数，默认：1024\r\n      'sink.buffer-flush.interval' = '10000', -- 批量写时间间隔，默认：10000毫秒\r\n      'sink.all-replace' = 'true', -- 解释如下(其他rdb数据库类似)：默认：false。定义了PRIMARY KEY才有效，否则是追加语句\r\n                                  -- sink.all-replace = 'true' 生成如：INSERT INTO `result3`(`mid`, `mbb`, `sid`, `sbb`) VALUES (?, ?, ?, ?) ON DUPLICATE KEY UPDATE `mid`=VALUES(`mid`), `mbb`=VALUES(`mbb`), `sid`=VALUES(`sid`), `sbb`=VALUES(`sbb`) 。会将所有的数据都替换。\r\n                                  -- sink.all-replace = 'false' 生成如：INSERT INTO `result3`(`mid`, `mbb`, `sid`, `sbb`) VALUES (?, ?, ?, ?) ON DUPLICATE KEY UPDATE `mid`=IFNULL(VALUES(`mid`),`mid`), `mbb`=IFNULL(VALUES(`mbb`),`mbb`), `sid`=IFNULL(VALUES(`sid`),`sid`), `sbb`=IFNULL(VALUES(`sbb`),`sbb`) 。如果新值为null，数据库中的旧值不为null，则不会覆盖。\r\n      'sink.parallelism' = '1'    -- 写入结果的并行度，默认：null\r\n      );\r\n\r\ninsert into sink\r\nselect id ,name,money,age,datethree,datesix\r\nfrom source_ods_fact_user_ippv;\r\n\r\n"}},"pageContext":{"id":"75e702cf-e164-5e3b-bd53-ddca2cb54b64","parent__id":"e397eb25-77d7-505a-8c37-7e3b9a6bd259","__params":{"parent__id":"e397eb25-77d7-505a-8c37-7e3b9a6bd259"}}},"staticQueryHashes":["1197112220","1410458087","527733040","63159454"]}